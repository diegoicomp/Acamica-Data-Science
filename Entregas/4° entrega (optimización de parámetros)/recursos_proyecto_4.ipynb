{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProyecto 4: Optimización de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Bienvenidos al cuarto (mini)proyecto de la carrera de Data Science de Acamica! \n",
    "\n",
    "En este proyecto vamos a seguir trabajando (por última vez) con el dataset de propiedades en venta publicadas en el portal [Properati](www.properati.com.ar). El objetivo en este caso es optimizar los parámetros de los algoritmos que usamos en el proyecto pasado.\n",
    "\n",
    "El dataset es el mismo del proyecto 3. Recordemos que las columnas que se agregan son:\n",
    "\n",
    "* `barrios_match`: si coincide el barrio publicado con el geográfico vale 1, si no 0.\n",
    "\n",
    "* `PH`, `apartment`, `house`: variables binarias que indican el tipo de propiedad.\n",
    "\n",
    "* dummies de barrios: variables binarias con 1 o 0 según el barrio.\n",
    "\n",
    "La métrica que vamos a usar para medir es RMSE (raíz del error cuadréatico medio), cuya fórmula es:\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{\\sum_{t=1}^n (\\hat y_t - y_t)^2}{n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Levantamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "path_dataset = 'dataset/datos_properati_limpios_model.csv'\n",
    "df = pd.read_csv(path_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separá** el dataset en entrenamiento (80%) y test (20%) utilizando como target la columna `price_aprox_usd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100 1276\n"
     ]
    }
   ],
   "source": [
    "# Hacé la separación en esta celda\n",
    "X = df.drop(['price_aprox_usd'], axis=1)\n",
    "y = df['price_aprox_usd']\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para repasar los parámetros de árboles de decisión en Scikit-learn: \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar veamos como hacer cross validation. Para eso necesitamos definir la cantidad de folds, en este caso vamos a usar 5.\n",
    "\n",
    "GridSearchCV nos permite testear a través de un espacio de búsqueda de parámetros la mejor combinación posible dado un estimador.\n",
    "\n",
    "Por ejemplo, en este caso probamos la profundidad máxima y la máxima cantidad de features para hacer los split. Ambos entre 1 y 5.\n",
    "Recordemos que para hacer la optimización scikit-learn usa la métrica `neg_mean_squared_error` en lugar de `mean_squared_error`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creá** una variable `param_grid` con valores del 1 al 5 para los atributos `max_depth` y `max_features`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creá en esta celda la variable param_grid\n",
    "param_grid = [{'max_depth': [1,2,3,4,5], 'max_features': [1,2,3,4,5]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importá** `GridSearchCV` y `DecisionTreeRegressor`.\n",
    "\n",
    "**Creá** una variable `grid_search` y asignale un `GridSearchCV` que recorra el `param_grid` que creaste con el algoritmos `DecisionTreeRegressor` y el un scoring de `neg_mean_squared_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa y crea un GridSearchCV en esta celda\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "grid_search = GridSearchCV(tree_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                          return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, realizá el `fit` del `grid_search` con el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeRegressor(criterion='mse', max_depth=None,\n",
       "                                             max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort=False, random_state=None,\n",
       "                                             splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'max_depth': [1, 2, 3, 4, 5],\n",
       "                          'max_features': [1, 2, 3, 4, 5]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hace el fit de grid search en esta celda\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisemos los resultados. Recordemos que no están expresados en RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(mean_squared_error, greater_is_better=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.scorer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mostrá** los `grid_scores` obtenidos durante el `grid_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.76444113e+08, -9.68694827e+08, -9.77620111e+08, -9.54932543e+08,\n",
       "       -8.32055332e+08, -9.74678322e+08, -9.27733804e+08, -8.40292940e+08,\n",
       "       -8.41322012e+08, -9.24757903e+08, -9.64017813e+08, -9.57672065e+08,\n",
       "       -8.83039907e+08, -8.05268054e+08, -8.09132193e+08, -9.51761668e+08,\n",
       "       -8.50626246e+08, -8.71040020e+08, -7.90310515e+08, -7.99582705e+08,\n",
       "       -9.36226354e+08, -8.34110127e+08, -7.41024824e+08, -7.05737190e+08,\n",
       "       -8.22237438e+08])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrá los grid_scores en esta celda\n",
    "scores = grid_search.cv_results_['mean_train_score']\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera, el valor con mejor resultado (dado el espacio de búsqueda definido) es `max_depth` 3 y `max_features` 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mostrá** el mejor score y los mejores parámetros encontrados por `grid_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'max_features': 4}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrás los resultados en esta celda\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos a RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmsq2rmse(score):\n",
    "    return np.round(np.sqrt(-score), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Encontrar el mejor modelo para el espacio de búsqueda dado__\n",
    "\n",
    "* `\"min_samples_split\": [2, 10, 20]`\n",
    "* `\"max_depth\": [None, 2, 5, 10, 15]`\n",
    "* `\"min_samples_leaf\": [1, 5, 10, 15]`\n",
    "* `\"max_leaf_nodes\": [None, 5, 10, 20]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que `GridSearchCV` tiene como parámetro default `refit=True`. Esto significa que luego de hacer la corrida se ajusta el mejor modelo al conjunto de datos de entrada. De esta manera, se puede predecir directamente usando `best_estimator_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimised_decision_tree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluemos en testing el desempeño de este modelo.__\n",
    "\n",
    "Como venimos trabajando, el resultado en testing será la medición que usaremos como benchmark para comparar este modelos con otros en el futuro, puesto que no estuvo en contacto con el dataset de test para la calibración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_opt_pred = optimised_decision_tree.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_opt_pred))\n",
    "np.round(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos los primeros 10 resultados de la predicción del valor de propiedades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_real = pd.Series(y_test.values)\n",
    "val_pred = pd.Series(y_opt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = pd.concat([val_real.rename('Valor real'),val_pred.rename('Valor Pred') ,abs(val_real-val_pred).rename('Dif(+/-)')] ,  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
